% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/information_theory.R
\name{gain}
\alias{gain}
\title{Information gain between two texts}
\usage{
gain(text_p, text_q, level = c("word", "letter"))
}
\arguments{
\item{text_p}{Local source}

\item{text_q}{Global source}

\item{level}{"word" or "letter"}
}
\value{
Gained information bits, that is: (H(P) - H(P,Q))
}
\description{
Here we try to measure how much information we obtain from one state of the source and another, which is really useful in classification and in general in information theory apply to language projects
}
\examples{
# Example of information gain from two texts (Shannon, 1939)
text1 <- "Dear Dr. Bush, Off and on I have been working on an analysis of some of the fundamental properties of general systems for the transmission of intelligence, including telephony, radio, television, telegraphy, etc."
text2 <- "Of course, my main project is still the machine for performing symbolic mathematical operations; although I have made some progress in various outskirts of the problem I am still pretty much in the woods, so far as actual results are concerned and so can't tell you much about it. I have a set of circuits drawn up which actually will perform symbolic differentiation and integration on most functions, but the method is not quite general or natural enough to be perfectly satisfactory. Some of the general philosophy underlying the machine seems to evade me completely..."
gain(text1, text2, level = "word")

# Example of comparison between two datasets (selected_piantadosi and heart_of_darkness, available in langstats, remember to load them with data(dataset_name))
data(selected_piantadosi)
data(heart_of_darkness)


gain(selected_piantadosi, heart_of_darkness, level = "word")


}
