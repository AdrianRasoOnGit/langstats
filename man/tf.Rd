% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tf_idf.R
\name{tf}
\alias{tf}
\title{Term Frequency (TF)}
\usage{
tf(input, level = c("word", "letter"), token = c("regex", "transformer"))
}
\arguments{
\item{input}{A text vector or a data frame, either raw text or a tidy token-frequency structure from this package or another source}

\item{level}{The level of analysis: currently accepts "word" or "letter"}

\item{token}{The method for token extraction: a "regex"-based approach or a neural "transformer" model (BERT)}
}
\value{
A data frame with the following structure
}
\description{
Through  we compute the term frequency (TF) of linguistic elements across documents or structured input tables. This function leverages
}
\details{
If the input is a character vector, it is interpreted as a collection of documents. Each element will be tokenised (depending on the level and token method) and a frequency table will be created for each. If a data frame is passed, it is parsed to extract already available token-frequency information.
}
\examples{
text <- c("Codd is English", "Codd studied in Oxford", "Codd proposed the relational model in 1970")
tf(text, level = "word")

df <- data.frame(word = c("model", "relational", "Codd"), frequency = c(10, 3, 2))
tf(df, level = "word")

}
